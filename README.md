<div align="center">

# _ðŸ’Ž DeepCompress_

<div>
 A Dual Reward Strategy for Dynamically Exploring and Compressing Reasoning Chains
</div>
</div>

<div>
<br>

<div align="center">

[![Github](https://img.shields.io/badge/Code-000000?style=for-the-badge&logo=github&logoColor=white)](https://github.com/Skytliang/DeepCompress)
[![arXiv](https://img.shields.io/badge/arXiv-2504.11456-b31b1b.svg?style=for-the-badge)](https://arxiv.org/abs/2510.27419)
</div>
</div>

## ðŸ”¥ News
- **January 26, 2026**: DeepCompress is accepted to ICLR 2026.


## ðŸ“– Overview


## ðŸ“š Citation
```bibtex
@article{liang2025deepcompress,
      title={DeepCompress: A Dual Reward Strategy for Dynamically Exploring and Compressing Reasoning Chains}, 
      author={Tian Liang and Wenxiang Jiao and Zhiwei He and Jiahao Xu and Haitao Mi and Dong Yu},
      year={2025},
      eprint={2510.27419},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2510.27419}, 
}
```
